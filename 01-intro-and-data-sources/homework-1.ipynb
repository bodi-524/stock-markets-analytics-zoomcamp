{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df7a831e",
   "metadata": {},
   "source": [
    "## Module 1 Homework (2025 cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6867632",
   "metadata": {},
   "source": [
    "### Question 1: [Index] S&P 500 Stocks Added to the Index\n",
    "\n",
    "**Which year had the highest number of additions?**\n",
    "\n",
    "Using the list of S&P 500 companies from Wikipedia's [S&P 500 companies page](https://en.wikipedia.org/wiki/List_of_S%26P_500_companies), download the data including the year each company was added to the index.\n",
    "\n",
    "Hint: you can use [pandas.read_html](https://pandas.pydata.org/docs/reference/api/pandas.read_html.html) to scrape the data into a DataFrame.\n",
    "\n",
    "Steps:\n",
    "1. Create a DataFrame with company tickers, names, and the year they were added.\n",
    "2. Extract the year from the addition date and calculate the number of stocks added each year.\n",
    "3. Which year had the highest number of additions (1957 doesn't count, as it was the year when the S&P 500 index was founded)? Write down this year as your answer (the most recent one, if you have several records).\n",
    "\n",
    "*Context*: \n",
    "> \"Following the announcement, all four new entrants saw their stock prices rise in extended trading on Friday\" - recent examples of S&P 500 additions include DASH, WSM, EXE, TKO in 2025 ([Nasdaq article](https://www.nasdaq.com/articles/sp-500-reshuffle-dash-tko-expe-wsm-join-worth-buying))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66d715e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Fin Data Sources\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "#Data viz\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "\n",
    "import time\n",
    "from datetime import date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e7176cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_14988\\61133717.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sp500['Date added'] = pd.to_datetime(sp500['Date added']).dt.year\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date added</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Symbol\n",
       "Date added        \n",
       "1957            53\n",
       "2017            23"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables = pd.read_html(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n",
    "tables[0].head()\n",
    "name_date = ['Symbol', 'Date added']\n",
    "sp500 = tables[0][name_date]\n",
    "sp500['Date added'] = pd.to_datetime(sp500['Date added']).dt.year\n",
    "sp500_years = sp500.groupby('Date added').count().sort_values(by='Symbol', ascending=False)\n",
    "\n",
    "sp500_years[0:2]\n",
    "#Since 1957 is the year the S&P 500 was created, the correct answer is 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621e86c",
   "metadata": {},
   "source": [
    "*Additional*: How many current S&P 500 stocks have been in the index for more than 20 years? When stocks are added to the S&P 500, they usually experience a price bump as investors and index funds buy shares following the announcement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e77caea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_14988\\2868978912.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sp500['Years since added'] = date.today().year - sp500['Date added']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "219"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500['Years since added'] = date.today().year - sp500['Date added']\n",
    "sp500 = sp500[sp500['Years since added'] > 20]\n",
    "sp500['Symbol'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f17f98",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 2. [Macro] Indexes YTD (as of 1 May 2025)\n",
    "\n",
    "**How many indexes (out of 10) have better year-to-date returns than the US (S&P 500) as of May 1, 2025?**\n",
    "\n",
    "Using Yahoo Finance World Indices data, compare the year-to-date (YTD) performance (1 January-1 May 2025) of major stock market indexes for the following countries:\n",
    "* United States - S&P 500 (^GSPC)\n",
    "* China - Shanghai Composite (000001.SS)\n",
    "* Hong Kong - HANG SENG INDEX (^HSI)\t\n",
    "* Australia - S&P/ASX 200 (^AXJO)\n",
    "* India - Nifty 50 (^NSEI)\n",
    "* Canada - S&P/TSX Composite (^GSPTSE)\n",
    "* Germany - DAX (^GDAXI)\n",
    "* United Kingdom - FTSE 100 (^FTSE)\n",
    "* Japan - Nikkei 225 (^N225)\n",
    "* Mexico - IPC Mexico (^MXX)\n",
    "* Brazil - Ibovespa (^BVSP)\n",
    "\n",
    "*Hint*: use start_date='2025-01-01' and end_date='2025-05-01' when downloading daily data in yfinance\n",
    "\n",
    "Context: \n",
    "> [Global Valuations: Who's Cheap, Who's Not?](https://simplywall.st/article/beyond-the-us-global-markets-after-yet-another-tariff-update) article suggests \"Other regions may be growing faster than the US and you need to diversify.\"\n",
    "\n",
    "Reference: Yahoo Finance World Indices - https://finance.yahoo.com/world-indices/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "61c05e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for S&P 500 (US) (^GSPC)...\n",
      "Fetching data for Shanghai Composite (China) (000001.SS)...\n",
      "Fetching data for Hang Seng (Hong Kong) (^HSI)...\n",
      "Fetching data for S&P/ASX 200 (Australia) (^AXJO)...\n",
      "Fetching data for Nifty 50 (India) (^NSEI)...\n",
      "Fetching data for S&P/TSX Composite (Canada) (^GSPTSE)...\n",
      "Fetching data for DAX (Germany) (^GDAXI)...\n",
      "Fetching data for FTSE 100 (UK) (^FTSE)...\n",
      "Fetching data for Nikkei 225 (Japan) (^N225)...\n",
      "Fetching data for IPC Mexico (Mexico) (^MXX)...\n",
      "Fetching data for Ibovespa (Brazil) (^BVSP)...\n",
      "\n",
      "--- Year-to-Date Performance (1 Jan 2025 - 1 May 2025) ---\n",
      "                Index Name    Ticker  YTD Performance (%)\n",
      "       IPC Mexico (Mexico)      ^MXX            13.049444\n",
      "     Hang Seng (Hong Kong)      ^HSI            12.720018\n",
      "         Ibovespa (Brazil)     ^BVSP            12.438710\n",
      "             DAX (Germany)    ^GDAXI            12.346378\n",
      "             FTSE 100 (UK)     ^FTSE             2.842590\n",
      "          Nifty 50 (India)     ^NSEI             2.490424\n",
      "Shanghai Composite (China) 000001.SS             0.504817\n",
      "S&P/TSX Composite (Canada)   ^GSPTSE            -0.226126\n",
      "   S&P/ASX 200 (Australia)     ^AXJO            -0.914500\n",
      "              S&P 500 (US)     ^GSPC            -5.103301\n",
      "        Nikkei 225 (Japan)     ^N225            -8.297931\n"
     ]
    }
   ],
   "source": [
    "ticker_map = {\n",
    "    'S&P 500 (US)': '^GSPC',\n",
    "    'Shanghai Composite (China)': '000001.SS', # Corrected ticker\n",
    "    'Hang Seng (Hong Kong)': '^HSI',\n",
    "    'S&P/ASX 200 (Australia)': '^AXJO',\n",
    "    'Nifty 50 (India)': '^NSEI',\n",
    "    'S&P/TSX Composite (Canada)': '^GSPTSE',\n",
    "    'DAX (Germany)': '^GDAXI',\n",
    "    'FTSE 100 (UK)': '^FTSE',\n",
    "    'Nikkei 225 (Japan)': '^N225',\n",
    "    'IPC Mexico (Mexico)': '^MXX',\n",
    "    'Ibovespa (Brazil)': '^BVSP'\n",
    "}\n",
    "\n",
    "# Define the start and end dates for the YTD performance\n",
    "start_date = '2025-01-01'\n",
    "end_date = '2025-05-01'\n",
    "\n",
    "# 1. Initialize an empty list to store results before the loop.\n",
    "performance_data = []\n",
    "\n",
    "# Fetch the data for each ticker\n",
    "for name, ticker in ticker_map.items():\n",
    "    try:\n",
    "        print(f\"Fetching data for {name} ({ticker})...\")\n",
    "        data = yf.Ticker(ticker).history(start=start_date, end=end_date)\n",
    "\n",
    "        # 2. Check if the DataFrame is empty before trying to access data.\n",
    "        if not data.empty:\n",
    "            # 3. Use .iloc for robust, position-based indexing.\n",
    "            start_price = data['Close'].iloc[0]\n",
    "            end_price = data['Close'].iloc[-1]\n",
    "            ytd_performance = (end_price - start_price) / start_price * 100\n",
    "\n",
    "            # 4. Append the result dictionary to the list.\n",
    "            performance_data.append({\n",
    "                'Index Name': name,\n",
    "                'Ticker': ticker,\n",
    "                'YTD Performance (%)': ytd_performance\n",
    "            })\n",
    "        else:\n",
    "            print(f\"-> No data found for {ticker} in the specified date range.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"-> Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "# 5. Create the DataFrame once from the list of results after the loop.\n",
    "if performance_data:\n",
    "    ytd_df = pd.DataFrame(performance_data)\n",
    "\n",
    "    # Sort the DataFrame by performance in descending order\n",
    "    ytd_df_sorted = ytd_df.sort_values(by='YTD Performance (%)', ascending=False)\n",
    "\n",
    "    print(\"\\n--- Year-to-Date Performance (1 Jan 2025 - 1 May 2025) ---\")\n",
    "    # Use to_string() to display the full DataFrame without truncation\n",
    "    print(ytd_df_sorted.to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nCould not retrieve performance data for any of the tickers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91f6db",
   "metadata": {},
   "source": [
    "*Additional*: How many of these indexes have better returns than the S&P 500 over 3, 5, and 10 year periods? Do you see the same trend?\n",
    "Note: For simplicity, ignore currency conversion effects.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "74cc03b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for S&P 500 (US) (^GSPC)...\n",
      "Fetching data for Shanghai Composite (China) (000001.SS)...\n",
      "Fetching data for Hang Seng (Hong Kong) (^HSI)...\n",
      "Fetching data for S&P/ASX 200 (Australia) (^AXJO)...\n",
      "Fetching data for Nifty 50 (India) (^NSEI)...\n",
      "Fetching data for S&P/TSX Composite (Canada) (^GSPTSE)...\n",
      "Fetching data for DAX (Germany) (^GDAXI)...\n",
      "Fetching data for FTSE 100 (UK) (^FTSE)...\n",
      "Fetching data for Nikkei 225 (Japan) (^N225)...\n",
      "Fetching data for IPC Mexico (Mexico) (^MXX)...\n",
      "Fetching data for Ibovespa (Brazil) (^BVSP)...\n",
      "\n",
      "--- Year-to-Date Performance 3 years ---\n",
      "                Index Name    Ticker  YTD Performance (%)\n",
      "             DAX (Germany)    ^GDAXI            61.395129\n",
      "          Nifty 50 (India)     ^NSEI            42.562875\n",
      "        Nikkei 225 (Japan)     ^N225            34.404756\n",
      "              S&P 500 (US)     ^GSPC            34.020480\n",
      "         Ibovespa (Brazil)     ^BVSP            26.658164\n",
      "S&P/TSX Composite (Canada)   ^GSPTSE            20.053451\n",
      "             FTSE 100 (UK)     ^FTSE            12.347091\n",
      "   S&P/ASX 200 (Australia)     ^AXJO            10.605692\n",
      "       IPC Mexico (Mexico)      ^MXX             8.425565\n",
      "Shanghai Composite (China) 000001.SS             6.886816\n",
      "     Hang Seng (Hong Kong)      ^HSI             4.821935\n",
      "Fetching data for S&P 500 (US) (^GSPC)...\n",
      "Fetching data for Shanghai Composite (China) (000001.SS)...\n",
      "Fetching data for Hang Seng (Hong Kong) (^HSI)...\n",
      "Fetching data for S&P/ASX 200 (Australia) (^AXJO)...\n",
      "Fetching data for Nifty 50 (India) (^NSEI)...\n",
      "Fetching data for S&P/TSX Composite (Canada) (^GSPTSE)...\n",
      "Fetching data for DAX (Germany) (^GDAXI)...\n",
      "Fetching data for FTSE 100 (UK) (^FTSE)...\n",
      "Fetching data for Nikkei 225 (Japan) (^N225)...\n",
      "Fetching data for IPC Mexico (Mexico) (^MXX)...\n",
      "Fetching data for Ibovespa (Brazil) (^BVSP)...\n",
      "\n",
      "--- Year-to-Date Performance 5 years ---\n",
      "                Index Name    Ticker  YTD Performance (%)\n",
      "          Nifty 50 (India)     ^NSEI           161.841063\n",
      "             DAX (Germany)    ^GDAXI           114.936570\n",
      "              S&P 500 (US)     ^GSPC            96.737219\n",
      "        Nikkei 225 (Japan)     ^N225            83.723618\n",
      "         Ibovespa (Brazil)     ^BVSP            71.239667\n",
      "S&P/TSX Composite (Canada)   ^GSPTSE            69.912379\n",
      "   S&P/ASX 200 (Australia)     ^AXJO            54.905743\n",
      "       IPC Mexico (Mexico)      ^MXX            54.684126\n",
      "             FTSE 100 (UK)     ^FTSE            47.401576\n",
      "Shanghai Composite (China) 000001.SS            13.928827\n",
      "     Hang Seng (Hong Kong)      ^HSI            -6.328463\n",
      "Fetching data for S&P 500 (US) (^GSPC)...\n",
      "Fetching data for Shanghai Composite (China) (000001.SS)...\n",
      "Fetching data for Hang Seng (Hong Kong) (^HSI)...\n",
      "Fetching data for S&P/ASX 200 (Australia) (^AXJO)...\n",
      "Fetching data for Nifty 50 (India) (^NSEI)...\n",
      "Fetching data for S&P/TSX Composite (Canada) (^GSPTSE)...\n",
      "Fetching data for DAX (Germany) (^GDAXI)...\n",
      "Fetching data for FTSE 100 (UK) (^FTSE)...\n",
      "Fetching data for Nikkei 225 (Japan) (^N225)...\n",
      "Fetching data for IPC Mexico (Mexico) (^MXX)...\n",
      "Fetching data for Ibovespa (Brazil) (^BVSP)...\n",
      "\n",
      "--- Year-to-Date Performance 10 years ---\n",
      "                Index Name    Ticker  YTD Performance (%)\n",
      "          Nifty 50 (India)     ^NSEI           192.058866\n",
      "              S&P 500 (US)     ^GSPC           164.150565\n",
      "         Ibovespa (Brazil)     ^BVSP           135.497088\n",
      "             DAX (Germany)    ^GDAXI            93.608190\n",
      "        Nikkei 225 (Japan)     ^N225            84.548741\n",
      "S&P/TSX Composite (Canada)   ^GSPTSE            61.942786\n",
      "   S&P/ASX 200 (Australia)     ^AXJO            39.759912\n",
      "       IPC Mexico (Mexico)      ^MXX            24.361595\n",
      "             FTSE 100 (UK)     ^FTSE            21.598918\n",
      "     Hang Seng (Hong Kong)      ^HSI           -21.349909\n",
      "Shanghai Composite (China) 000001.SS           -26.814921\n"
     ]
    }
   ],
   "source": [
    "ticker_map = {\n",
    "    'S&P 500 (US)': '^GSPC',\n",
    "    'Shanghai Composite (China)': '000001.SS', # Corrected ticker\n",
    "    'Hang Seng (Hong Kong)': '^HSI',\n",
    "    'S&P/ASX 200 (Australia)': '^AXJO',\n",
    "    'Nifty 50 (India)': '^NSEI',\n",
    "    'S&P/TSX Composite (Canada)': '^GSPTSE',\n",
    "    'DAX (Germany)': '^GDAXI',\n",
    "    'FTSE 100 (UK)': '^FTSE',\n",
    "    'Nikkei 225 (Japan)': '^N225',\n",
    "    'IPC Mexico (Mexico)': '^MXX',\n",
    "    'Ibovespa (Brazil)': '^BVSP'\n",
    "}\n",
    "\n",
    "# Define the start and end dates for the YTD performance\n",
    "start_list = ['2022-05-01', '2020-05-01', '2015-05-01']\n",
    "end_date = '2025-05-01'\n",
    "\n",
    "# 1. Initialize an empty list to store results before the loop.\n",
    "performance_data = []\n",
    "\n",
    "for start_date in start_list:\n",
    "    # Fetch the data for each ticker\n",
    "    for name, ticker in ticker_map.items():\n",
    "        try:\n",
    "            print(f\"Fetching data for {name} ({ticker})...\")\n",
    "            data = yf.Ticker(ticker).history(start=start_date, end=end_date)\n",
    "\n",
    "            # 2. Check if the DataFrame is empty before trying to access data.\n",
    "            if not data.empty:\n",
    "                # 3. Use .iloc for robust, position-based indexing.\n",
    "                start_price = data['Close'].iloc[0]\n",
    "                end_price = data['Close'].iloc[-1]\n",
    "                ytd_performance = (end_price - start_price) / start_price * 100\n",
    "\n",
    "                # 4. Append the result dictionary to the list.\n",
    "                performance_data.append({\n",
    "                    'Index Name': name,\n",
    "                    'Ticker': ticker,\n",
    "                    'YTD Performance (%)': ytd_performance\n",
    "                })\n",
    "            else:\n",
    "                print(f\"-> No data found for {ticker} in the specified date range.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"-> Error fetching data for {ticker}: {e}\")\n",
    "\n",
    "    # 5. Create the DataFrame once from the list of results after the loop.\n",
    "    if performance_data:\n",
    "        ytd_df = pd.DataFrame(performance_data)\n",
    "        # Sort the DataFrame by performance in descending order\n",
    "        ytd_df_sorted = ytd_df.sort_values(by='YTD Performance (%)', ascending=False)\n",
    "        print(f\"\\n--- Year-to-Date Performance {int(end_date[:4]) - int(start_date[:4])} years ---\")\n",
    "\n",
    "                # Use to_string() to display the full DataFrame without truncation\n",
    "        print(ytd_df_sorted.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nCould not retrieve performance data for any of the tickers.\")\n",
    "    #Clear the performance data for the next iteration\n",
    "    performance_data.clear()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542f41e",
   "metadata": {},
   "source": [
    "### Question 3. [Index] S&P 500 Market Corrections Analysis\n",
    "\n",
    "\n",
    "**Calculate the median duration (in days) of significant market corrections in the S&P 500 index.**\n",
    "\n",
    "For this task, define a correction as an event when a stock index goes down by **more than 5%** from the closest all-time high maximum.\n",
    "\n",
    "Steps:\n",
    "1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "2. Identify all-time high points (where price exceeds all previous prices)\n",
    "3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "4. Calculate drawdown percentages: (high - low) / high × 100\n",
    "5. Filter for corrections with at least 5% drawdown\n",
    "6. Calculate the duration in days for each correction period\n",
    "7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "*Context:* \n",
    "> * Investors often wonder about the typical length of market corrections when deciding \"when to buy the dip\" ([Reddit discussion](https://www.reddit.com/r/investing/comments/1jrqnte/when_are_you_buying_the_dip/?rdt=64135)).\n",
    "\n",
    "> * [A Wealth of Common Sense - How Often Should You Expect a Stock Market Correction?](https://awealthofcommonsense.com/2022/01/how-often-should-you-expect-a-stock-market-correction/)\n",
    "\n",
    "*Hint (use this data to compare with your results)*: Here is the list of top 10 largest corrections by drawdown:\n",
    "* 2007-10-09 to 2009-03-09: 56.8% drawdown over 517 days\n",
    "* 2000-03-24 to 2002-10-09: 49.1% drawdown over 929 days\n",
    "* 1973-01-11 to 1974-10-03: 48.2% drawdown over 630 days\n",
    "* 1968-11-29 to 1970-05-26: 36.1% drawdown over 543 days\n",
    "* 2020-02-19 to 2020-03-23: 33.9% drawdown over 33 days\n",
    "* 1987-08-25 to 1987-12-04: 33.5% drawdown over 101 days\n",
    "* 1961-12-12 to 1962-06-26: 28.0% drawdown over 196 days\n",
    "* 1980-11-28 to 1982-08-12: 27.1% drawdown over 622 days\n",
    "* 2022-01-03 to 2022-10-12: 25.4% drawdown over 282 days\n",
    "* 1966-02-09 to 1966-10-07: 22.2% drawdown over 240 days\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "36160967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-10-09 to 2013-03-28: 55.6% drawdown over 1997 days\n",
      "2000-03-24 to 2007-05-30: 47.7% drawdown over 2622 days\n",
      "1973-01-11 to 1980-07-17: 47.4% drawdown over 2743 days\n",
      "1968-11-29 to 1972-03-06: 34.3% drawdown over 1193 days\n",
      "1987-08-25 to 1989-07-26: 33.0% drawdown over 701 days\n",
      "2020-02-19 to 2020-08-18: 32.1% drawdown over 180 days\n",
      "1961-12-12 to 1963-09-03: 27.3% drawdown over 629 days\n",
      "1980-11-28 to 1982-11-03: 26.7% drawdown over 705 days\n",
      "2022-01-03 to 2024-01-19: 24.8% drawdown over 746 days\n",
      "1956-08-03 to 1958-09-24: 21.5% drawdown over 782 days\n",
      "\n",
      "--- Correction Durations Percentiles ---\n",
      "25th Percentile: 70.5 days\n",
      "50th Percentile (Median): 116.5 days\n",
      "75th Percentile: 340.75 days\n"
     ]
    }
   ],
   "source": [
    "# 1. Download S&P 500 historical data (1950-present) using yfinance\n",
    "start_date = '1950-01-01'\n",
    "end_date = date.today()\n",
    "\n",
    "snp500 = yf.Ticker('^GSPC').history(start=start_date, end=end_date)\n",
    "\n",
    "# 2. Identify all-time high points (where price exceeds all previous prices)\n",
    "snp500['All Time High'] = snp500['Close'].cummax()\n",
    "snp500['Is_ATH'] = snp500['Close'] >= snp500['All Time High']\n",
    "all_time_highs = snp500[snp500['Is_ATH']].copy()\n",
    "all_time_highs\n",
    "\n",
    "# 3. For each pair of consecutive all-time highs, find the minimum price in between\n",
    "corrections = []\n",
    "for\ti in range(len(all_time_highs)-1):\n",
    "\t# Get the current and previous all-time high\n",
    "\tstart_ath_date = all_time_highs.index[i]\n",
    "\tend_ath_date = all_time_highs.index[i+1]\n",
    "\tstart_high_price = all_time_highs['All Time High'].iloc[i]\n",
    "\tperiod_between_highs = snp500[start_ath_date:end_ath_date]\n",
    "\tmin_price_in_period = period_between_highs['High'].min()\n",
    "\tmin_price_date = period_between_highs['High'].idxmin()\n",
    "\n",
    "# 4. Calculate drawdown percentages: (high - low) / high × 100\n",
    "\tdrawdown = (start_high_price - min_price_in_period) / start_high_price * 100\n",
    "\t\n",
    "\tcorrections.append({\n",
    "        'Start_Date': start_ath_date,\n",
    "        'Start_High': start_high_price,\n",
    "        'Min_Price_Date': min_price_date,\n",
    "        'Min_Price': min_price_in_period,\n",
    "        'End_Date': end_ath_date,\n",
    "        'Drawdown_Percent': drawdown\n",
    "    })\n",
    "\n",
    "corrections_df = pd.DataFrame(corrections)\n",
    "\n",
    "corrections_df\n",
    "# 5. Filter for corrections with at least 5% drawdown\n",
    "significant_corrections = corrections_df[corrections_df['Drawdown_Percent'] >= 5].copy()\n",
    "# 6. Calculate the duration in days for each correction period\n",
    "significant_corrections['Duration'] = (significant_corrections['End_Date'] - significant_corrections['Start_Date']).dt.days\n",
    "\n",
    "# Check with the top 10 most significant corrections\n",
    "# Value does not match, WHY?\n",
    "significant_corrections_check = significant_corrections.sort_values(by='Drawdown_Percent', ascending=False).head(10)\n",
    "for index, row in significant_corrections_check.iterrows():\n",
    "\tstart_date = row['Start_Date'].strftime('%Y-%m-%d')\n",
    "\tend_date = row['End_Date'].strftime('%Y-%m-%d')\n",
    "\tdrawdown_percent = row['Drawdown_Percent']\n",
    "\tduration_days = (row['End_Date'] - row['Start_Date']).days\n",
    "\tprint(f\"{start_date} to {end_date}: {drawdown_percent:.1f}% drawdown over {duration_days} days\")\n",
    "\n",
    "# 7. Determine the 25th, 50th (median), and 75th percentiles for correction durations\n",
    "\n",
    "percentiles = significant_corrections['Duration'].quantile([0.25, 0.5,0.75]).to_dict()\n",
    "print(\"\\n--- Correction Durations Percentiles ---\")\n",
    "print(f\"25th Percentile: {percentiles[0.25]} days\")\n",
    "print(f\"50th Percentile (Median): {percentiles[0.5]} days\")\n",
    "print(f\"75th Percentile: {percentiles[0.75]} days\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b665696",
   "metadata": {},
   "source": [
    "### Question 4.  [Stocks] Earnings Surprise Analysis for Amazon (AMZN)\n",
    "\n",
    "\n",
    "**Calculate the median 2-day percentage change in stock prices following positive earnings surprises days.**\n",
    "\n",
    "Steps:\n",
    "1. Load earnings data from CSV ([ha1_Amazon.csv](ha1_Amazon.csv)) containing earnings dates, EPS estimates, and actual EPS. Make sure you are using the correct delimiter to read the data, such as in this command ```python pandas.read_csv(\"ha1_Amazon.csv\", delimiter=';') ```\n",
    "2. Download complete historical price data using yfinance\n",
    "3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), compute the *return* as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)\n",
    "4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\"). Both fields should be present in the file. You should obtain 36 data points for use in the descriptive analysis (median) later. \n",
    "5. Calculate 2-day percentage changes following positive earnings surprises. Show your answer in % (closest number to the 2nd digit): *return* * 100.0\n",
    "6. (Optional) Compare the median 2-day percentage change for positive surprises vs. all historical dates. Do you see the difference?\n",
    "\n",
    "Context: Earnings announcements, especially when they exceed analyst expectations, can significantly impact stock prices in the short term.\n",
    "\n",
    "Reference: Yahoo Finance earnings calendar - https://finance.yahoo.com/calendar/earnings?symbol=AMZN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4b732d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>2-Day Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997-05-15</td>\n",
       "      <td>0.121875</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.096354</td>\n",
       "      <td>0.097917</td>\n",
       "      <td>1443120000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1997-05-16</td>\n",
       "      <td>0.098438</td>\n",
       "      <td>0.098958</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>294000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1997-05-19</td>\n",
       "      <td>0.088021</td>\n",
       "      <td>0.088542</td>\n",
       "      <td>0.081250</td>\n",
       "      <td>0.085417</td>\n",
       "      <td>122136000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.765910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1997-05-20</td>\n",
       "      <td>0.086458</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>109344000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.421125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1997-05-21</td>\n",
       "      <td>0.081771</td>\n",
       "      <td>0.082292</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>377064000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16.463936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7065</th>\n",
       "      <td>2025-06-16</td>\n",
       "      <td>212.309998</td>\n",
       "      <td>217.059998</td>\n",
       "      <td>211.600006</td>\n",
       "      <td>216.100006</td>\n",
       "      <td>33284200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.341212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7066</th>\n",
       "      <td>2025-06-17</td>\n",
       "      <td>215.199997</td>\n",
       "      <td>217.410004</td>\n",
       "      <td>214.559998</td>\n",
       "      <td>214.820007</td>\n",
       "      <td>32086300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.282414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7067</th>\n",
       "      <td>2025-06-18</td>\n",
       "      <td>215.089996</td>\n",
       "      <td>217.960007</td>\n",
       "      <td>212.339996</td>\n",
       "      <td>212.520004</td>\n",
       "      <td>44360500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.656641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7068</th>\n",
       "      <td>2025-06-20</td>\n",
       "      <td>214.679993</td>\n",
       "      <td>214.889999</td>\n",
       "      <td>208.270004</td>\n",
       "      <td>209.690002</td>\n",
       "      <td>75297800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.388048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7069</th>\n",
       "      <td>2025-06-23</td>\n",
       "      <td>209.889999</td>\n",
       "      <td>210.389999</td>\n",
       "      <td>207.310104</td>\n",
       "      <td>208.365005</td>\n",
       "      <td>29244237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.955109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7070 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date        Open        High         Low       Close      Volume  \\\n",
       "0    1997-05-15    0.121875    0.125000    0.096354    0.097917  1443120000   \n",
       "1    1997-05-16    0.098438    0.098958    0.085417    0.086458   294000000   \n",
       "2    1997-05-19    0.088021    0.088542    0.081250    0.085417   122136000   \n",
       "3    1997-05-20    0.086458    0.087500    0.081771    0.081771   109344000   \n",
       "4    1997-05-21    0.081771    0.082292    0.068750    0.071354   377064000   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "7065 2025-06-16  212.309998  217.059998  211.600006  216.100006    33284200   \n",
       "7066 2025-06-17  215.199997  217.410004  214.559998  214.820007    32086300   \n",
       "7067 2025-06-18  215.089996  217.960007  212.339996  212.520004    44360500   \n",
       "7068 2025-06-20  214.679993  214.889999  208.270004  209.690002    75297800   \n",
       "7069 2025-06-23  209.889999  210.389999  207.310104  208.365005    29244237   \n",
       "\n",
       "      Dividends  Stock Splits  2-Day Return  \n",
       "0           0.0           0.0           NaN  \n",
       "1           0.0           0.0           NaN  \n",
       "2           0.0           0.0    -12.765910  \n",
       "3           0.0           0.0     -5.421125  \n",
       "4           0.0           0.0    -16.463936  \n",
       "...         ...           ...           ...  \n",
       "7065        0.0           0.0      1.341212  \n",
       "7066        0.0           0.0      1.282414  \n",
       "7067        0.0           0.0     -1.656641  \n",
       "7068        0.0           0.0     -2.388048  \n",
       "7069        0.0           0.0     -1.955109  \n",
       "\n",
       "[7070 rows x 9 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1. Load earnings data from CSV \n",
    "\n",
    "earnings_data = pd.read_csv(\"D:/vapi_phase/Finance/Repo/stock-markets-analytics-zoomcamp/cohorts/2025/ha1_Amazon.csv\", delimiter=';')\n",
    "earnings_data.head(50)\n",
    "\n",
    "# 2. Download complete historical price data using yfinance\n",
    "ticker = 'AMZN'\n",
    "start_date = '1997-05-15'\n",
    "end_date = date.today()\n",
    "historical_prices = yf.Ticker(ticker).history(start=start_date, end=end_date)\n",
    "\n",
    "# 3. Calculate 2-day percentage changes for all historical dates: for each sequence of 3 consecutive trading days (Day 1, Day 2, Day 3), \n",
    "# compute the *return* as Close_Day3 / Close_Day1 - 1. (Assume Day 2 may correspond to the earnings announcement.)\n",
    "historical_prices['2-Day Return'] = historical_prices['Close'].pct_change(periods=2) * 100.0\n",
    "historical_prices.index = historical_prices.index.strftime('%Y-%m-%d')\n",
    "historical_prices.reset_index(inplace=True)\n",
    "historical_prices['Date'] = pd.to_datetime(historical_prices['Date'])\n",
    "\n",
    "# 4. Identify positive earnings surprises (where \"actual EPS > estimated EPS\"). \n",
    "# Both fields should be present in the file. You should obtain 36 data points for use in the descriptive analysis (median) later. \n",
    "columns_to_clean = ['EPS Estimate', 'Reported EPS']\n",
    "\n",
    "for col in columns_to_clean:\n",
    "\tearnings_data[col] = earnings_data[col].astype(str).str.replace(r'[^0-9.-]', '', regex=True)\n",
    "\tearnings_data[col] = earnings_data[col].replace(['', '-', '.'], np.nan)\n",
    "\tearnings_data = earnings_data[earnings_data[col].notna()]\n",
    "\tearnings_data[col] = pd.to_numeric(earnings_data[col])\n",
    "earnings_data['Positive Surprise'] = earnings_data['Reported EPS'] > earnings_data['EPS Estimate']\n",
    "earnings_data_positive = earnings_data[earnings_data['Positive Surprise']].copy()\n",
    "earnings_data_positive.reset_index(drop=True, inplace=True)\n",
    "historical_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "006ce235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Calculate 2-day percentage changes following positive earnings surprises. \n",
    "# Show your answer in % (closest number to the 2nd digit): *return* * 100.0\n",
    "\n",
    "earnings_data_positive['Earnings Date'] = pd.to_datetime(earnings_data_positive['Earnings Date'])\n",
    "earnings_data_positive['Earnings Date'] = earnings_data_positive['Earnings Date'].dt.date\n",
    "earnings_data_positive['Earnings Date'] = earnings_data_positive['Earnings Date'].astype(str)\n",
    "historical_prices['Date'] = historical_prices['Date'].astype(str)\n",
    "# just add historical_prices['2-Day Return'] to the earnings_data_positive['2-Day Return'] where the dates match\n",
    "\n",
    "earnings_compiled = earnings_data_positive.merge(historical_prices[['Date','2-Day Return']], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\tleft_on='Earnings Date', right_on='Date', how='left')\n",
    "\n",
    "earnings_compiled\n",
    "earnings_compiled['2-Day Return'] = earnings_compiled['2-Day Return'].astype(float)\n",
    "earnings_compiled['2-Day Return'] = earnings_compiled['2-Day Return'].round(2)\n",
    "# Median 2-day percentage change in AMZN stock price following positive surprise earnings days\n",
    "earnings_compiled['2-Day Return'].median()\n",
    "# earnings_compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "235d1cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6. (Optional) Compare the median 2-day percentage change for positive surprises vs. all historical dates. Do you see the difference?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
